{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.I for S.E.A: Grab Safety Challenge"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the telematics data for each trip and the label if the trip is tagged as dangerous driving, derive a model that can detect dangerous driving trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given dataset contains telematics data during trips (bookingID). Each trip will be assigned with label 1 or 0 in a separate label file to indicate dangerous driving. Pls take note that dangerous drivings are labelled per trip, while each trip could contain thousands of telematics data points. participants are supposed to create the features based on the telematics data before training models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset description:\n",
    "\n",
    "    bookingID - Trip ID\n",
    "    Accuracy - accuracy inferred by GPS in meters\n",
    "    Bearing - GPS bearing in degree\n",
    "    acceleration_x - accelerometer reading at x axis (m/s2)\n",
    "    acceleration_y - accelerometer reading at y axis (m/s2)\n",
    "    acceleration_z - accelerometer reading at z axis (m/s2)\n",
    "    gyro_x - gyroscope reading in x axis (rad/s)\n",
    "    gyro_y - gyroscope reading in y axis (rad/s)\n",
    "    gyro_z - gyroscope reading in z axis (rad/s)\n",
    "    second - time of the record by number of seconds\n",
    "    Speed - speed measured by GPS in m/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from botocore.client import Config\n",
    "import ibm_boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@hidden_cell\n",
    "#Specific for IBM cloud\n",
    "#Accessing datasets\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "client_fd12f0b669894704a4fb8d23106771b7 = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='qpDkAxz61wZPpjHhXp-IRBQ442XuNOj1yoo24LoWMiQT',\n",
    "    ibm_auth_endpoint=\"https://iam.bluemix.net/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.ap-geo.objectstorage.service.networklayer.com')\n",
    "\n",
    "body = client_fd12f0b669894704a4fb8d23106771b7.get_object(Bucket='ai4sea-donotdelete-pr-bdgb3pzwo6vigg',Key='part-00000-e9445087-aa0a-433b-a7f6-7f4c19d78ad6-c000_lookup.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "df_data_label = pd.read_csv(body)\n",
    "#df_data_label.head()\n",
    "\n",
    "body0 = client_fd12f0b669894704a4fb8d23106771b7.get_object(Bucket='ai4sea-donotdelete-pr-bdgb3pzwo6vigg',Key='part-00000-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body0, \"__iter__\"): body0.__iter__ = types.MethodType( __iter__, body0 )\n",
    "\n",
    "df_data_0 = pd.read_csv(body0)\n",
    "#df_data_0.head()\n",
    "\n",
    "body1 = client_fd12f0b669894704a4fb8d23106771b7.get_object(Bucket='ai4sea-donotdelete-pr-bdgb3pzwo6vigg',Key='part-00001-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body1, \"__iter__\"): body1.__iter__ = types.MethodType( __iter__, body1 )\n",
    "\n",
    "df_data_1 = pd.read_csv(body1)\n",
    "#df_data_1.head()\n",
    "\n",
    "body2 = client_fd12f0b669894704a4fb8d23106771b7.get_object(Bucket='ai4sea-donotdelete-pr-bdgb3pzwo6vigg',Key='part-00002-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body2, \"__iter__\"): body2.__iter__ = types.MethodType( __iter__, body2 )\n",
    "\n",
    "df_data_2 = pd.read_csv(body2)\n",
    "#df_data_2.head()\n",
    "\n",
    "body3 = client_fd12f0b669894704a4fb8d23106771b7.get_object(Bucket='ai4sea-donotdelete-pr-bdgb3pzwo6vigg',Key='part-00003-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body3, \"__iter__\"): body3.__iter__ = types.MethodType( __iter__, body3 )\n",
    "\n",
    "df_data_3 = pd.read_csv(body3)\n",
    "#df_data_3.head()\n",
    "\n",
    "body4 = client_fd12f0b669894704a4fb8d23106771b7.get_object(Bucket='ai4sea-donotdelete-pr-bdgb3pzwo6vigg',Key='part-00004-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body4, \"__iter__\"): body4.__iter__ = types.MethodType( __iter__, body4 )\n",
    "\n",
    "df_data_4 = pd.read_csv(body4)\n",
    "#df_data_4.head()\n",
    "\n",
    "body5 = client_fd12f0b669894704a4fb8d23106771b7.get_object(Bucket='ai4sea-donotdelete-pr-bdgb3pzwo6vigg',Key='part-00005-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body5, \"__iter__\"): body5.__iter__ = types.MethodType( __iter__, body5 )\n",
    "\n",
    "df_data_5 = pd.read_csv(body5)\n",
    "#df_data_5.head()\n",
    "\n",
    "body6 = client_fd12f0b669894704a4fb8d23106771b7.get_object(Bucket='ai4sea-donotdelete-pr-bdgb3pzwo6vigg',Key='part-00006-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body6, \"__iter__\"): body6.__iter__ = types.MethodType( __iter__, body6 )\n",
    "\n",
    "df_data_6 = pd.read_csv(body6)\n",
    "#df_data_6.head()\n",
    "\n",
    "body7 = client_fd12f0b669894704a4fb8d23106771b7.get_object(Bucket='ai4sea-donotdelete-pr-bdgb3pzwo6vigg',Key='part-00007-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body7, \"__iter__\"): body7.__iter__ = types.MethodType( __iter__, body7 )\n",
    "\n",
    "df_data_7 = pd.read_csv(body7)\n",
    "#df_data_7.head()\n",
    "\n",
    "body8 = client_fd12f0b669894704a4fb8d23106771b7.get_object(Bucket='ai4sea-donotdelete-pr-bdgb3pzwo6vigg',Key='part-00008-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body8, \"__iter__\"): body8.__iter__ = types.MethodType( __iter__, body8 )\n",
    "\n",
    "df_data_8 = pd.read_csv(body8)\n",
    "#df_data_8.head()\n",
    "\n",
    "body9 = client_fd12f0b669894704a4fb8d23106771b7.get_object(Bucket='ai4sea-donotdelete-pr-bdgb3pzwo6vigg',Key='part-00009-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body9, \"__iter__\"): body9.__iter__ = types.MethodType( __iter__, body9 )\n",
    "\n",
    "df_data_9 = pd.read_csv(body9)\n",
    "#df_data_9.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_data_label = pd.read_csv(body)\n",
    "#df_data_0 = pd.read_csv(body0)\n",
    "#df_data_1 = pd.read_csv(body1)\n",
    "#df_data_2 = pd.read_csv(body2)\n",
    "#df_data_3 = pd.read_csv(body3)\n",
    "#df_data_4 = pd.read_csv(body4)\n",
    "#df_data_5 = pd.read_csv(body5)\n",
    "#df_data_6 = pd.read_csv(body6)\n",
    "#df_data_7 = pd.read_csv(body7)\n",
    "#df_data_8 = pd.read_csv(body8)\n",
    "#df_data_9 = pd.read_csv(body9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get index of rows with duplicates\n",
    "df_label_dup_index = df_data_label.loc[df_data_label.duplicated(subset = 'bookingID', keep = False) == True].sort_values(ascending = True, by = 'bookingID').index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicate bookingID in labeled-dataset to avoid inconsistencies in a booking record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with duplicate\n",
    "df_data_label.drop(labels = df_label_dup_index, axis = 'index' ,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge partial datasets (Grab safety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all dataset\n",
    "df_data = df_data_0.append([df_data_1, df_data_2, df_data_3, df_data_4, df_data_5, df_data_6, df_data_7, df_data_8, df_data_9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge dataset with label dataset\n",
    "df_data = df_data.merge(df_data_label, on = 'bookingID', how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_data.bookingID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_data.info(null_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin = df_data.groupby(by = ['label', 'bookingID'], as_index = False, sort = False).apply(lambda x: x.sort_values('second'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "included = ['bookingID','Accuracy','Bearing','second','Speed','label']\n",
    "df_fin.drop(labels = df_fin.columns.difference(included), axis = 'columns' ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fin.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin.bookingID = df_fin.bookingID.astype('category')\n",
    "#df_fin.label = df_fin.label.astype('category')\n",
    "#df_fin.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate dataset with respect to safety "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin_safe = df_fin.loc[df_fin['label']==0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin_nsafe = df_fin.loc[df_fin['label']==1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(' Unsafe telematics data shape:', df_fin_nsafe.shape, '\\n', 'Safe telematics data shape:', df_fin_safe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will enrich our labeled dataset with features that we will derive from telematics data. We will improve prediction by including (1) mean Accuracy, (2) std. dev. of Accuracy, (3) mean Speed, (4) max Speed, (5) mean longitude acceleration, (6) min longitude acceleration, (7) max longitude acceleration, (8) DSD score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### DSD scoring reference:\n",
    "\n",
    "Driving Behavior and Traffic Safety: http://www.ccsenet.org/journal/index.php/mas/article/view/29037"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DSD scoring\n",
    "\n",
    "We will determine (1) longitude acceleration and (2) latitude acceleration with respect to variables: 'Speed', 'second', & 'Bearing' interactions, and proceed on scoring the booking trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get change in variable\n",
    "def getdelta(df_, column_):\n",
    "    delta = []\n",
    "    for booking in df_.loc[:,'bookingID'].unique():\n",
    "        delta.append(0)\n",
    "        temp_df = np.array(df_.loc[df_['bookingID']==booking, column_])\n",
    "        rec_count = len(temp_df)\n",
    "        for i in range(rec_count-1):\n",
    "            num = (temp_df[i+1]) - (temp_df[i])\n",
    "            delta.append(num.round(3))\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to check if within limit area functions: A_, B_, C_, D_ \n",
    "def isInLimits(df_, column_x = 'acceleration_lat', column_y = 'acceleration_long'):\n",
    "    results = []\n",
    "    for i in df_.index:\n",
    "        x_val = df_.loc[i, column_x]\n",
    "        y_val = df_.loc[i, column_y]\n",
    "        if ((-2.5<= x_val <= 2.5) & (-3<=y_val<=2.5)):\n",
    "            A_ = 0.509*(x_val**2)+(2.351*x_val)+2.841\n",
    "            B_ = 0.509*(x_val**2)-(2.351*x_val)+2.841\n",
    "            C_ = 0.446*(x_val**2)+(2.395*x_val)-3.349\n",
    "            D_ = 0.446*(x_val**2)-(2.395*x_val)-3.349\n",
    "            if (y_val<=A_) & (y_val<=B_) & (y_val>=C_) & (y_val>=D_):\n",
    "                results.append(1)\n",
    "            else:\n",
    "                results.append(0)\n",
    "        else:\n",
    "            results.append(0)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define variables that can derive interactions\n",
    "df_fin_nsafe['delta_second'] = np.nan\n",
    "df_fin_nsafe.loc[:,'delta_second'] = getdelta(df_fin_nsafe.loc[:,:], 'second')\n",
    "df_fin_nsafe['delta_bearing'] = np.nan\n",
    "df_fin_nsafe.loc[:,'delta_bearing'] = getdelta(df_fin_nsafe.loc[:,:], 'Bearing')\n",
    "df_fin_nsafe['acceleration_long'] = np.nan\n",
    "df_fin_nsafe.loc[:,'acceleration_long'] = getdelta(df_fin_nsafe.loc[:,:], 'Speed')/df_fin_nsafe.loc[:,'delta_second']\n",
    "df_fin_nsafe['acceleration_lat'] = np.nan\n",
    "df_fin_nsafe.loc[:,'acceleration_lat'] = (df_fin_nsafe.loc[:,'Speed']**2)/((180*df_fin_nsafe.loc[:,'Speed'])/(np.pi*df_fin_nsafe.loc[:,'delta_bearing']))\n",
    "\n",
    "df_fin_safe['delta_second'] = np.nan\n",
    "df_fin_safe.loc[:,'delta_second'] = getdelta(df_fin_safe.loc[:,:], 'second')\n",
    "df_fin_safe['delta_bearing'] =np.nan\n",
    "df_fin_safe.loc[:,'delta_bearing'] = getdelta(df_fin_safe.loc[:,:], 'Bearing')\n",
    "df_fin_safe['acceleration_long'] = np.nan\n",
    "df_fin_safe.loc[:,'acceleration_long'] = getdelta(df_fin_safe.loc[:,:], 'Speed')/df_fin_safe.loc[:,'delta_second']\n",
    "df_fin_safe['acceleration_lat'] = np.nan\n",
    "df_fin_safe.loc[:,'acceleration_lat'] = (df_fin_safe.loc[:,'Speed']**2)/((180*df_fin_safe.loc[:,'Speed'])/(np.pi*df_fin_safe.loc[:,'delta_bearing']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace null values with 0 - this will replace latitude accelerations that suggests the car is moving straight, therefore 0 latitude acceleration\n",
    "df_fin_nsafe.loc[:,:].fillna(0, inplace = True)\n",
    "df_fin_safe.loc[:,:].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#check telematics data if its within safe area function, set records to 1 if latitude/longitude acceleration within limits\n",
    "df_fin_nsafe['within_limits'] = np.nan\n",
    "df_fin_nsafe.loc[:,'within_limits'] = isInLimits(df_fin_nsafe.loc[:,:])\n",
    "df_fin_safe['within_limits'] = np.nan\n",
    "df_fin_safe.loc[:,'within_limits'] = isInLimits(df_fin_safe.loc[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fin_safe.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set as new features\n",
    "df_features_safe = df_fin_safe.groupby('bookingID', as_index= True, sort = False).agg({'Speed': ['mean', 'max'], 'acceleration_long': ['mean', 'min', 'max'], 'within_limits': ['mean'], 'Accuracy': ['mean', 'std'], 'label':['min']})\n",
    "df_features_nsafe = df_fin_nsafe.groupby('bookingID', as_index= True, sort = False).agg({'Speed': ['mean', 'max'], 'acceleration_long': ['mean', 'min', 'max'], 'within_limits': ['mean'], 'Accuracy': ['mean', 'std'], 'label':['min']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_nsafe.dropna(inplace = True)\n",
    "df_features_safe.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_features_safe, df_features_nsafe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = []\n",
    "for i in df.columns:\n",
    "    if i[0] == 'within_limits':\n",
    "        new_cols.append('dsd_score')\n",
    "    elif i[0] == 'label':\n",
    "        new_cols.append('label')\n",
    "    else:\n",
    "        new_cols.append(i[0]+'_'+i[1])\n",
    "#print(new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tidying dataframes\n",
    "df.columns.droplevel(0)\n",
    "df.columns = new_cols\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formatiing DSD score\n",
    "df.dsd_score = 1-df.dsd_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>acceleration_long_mean</th>\n",
       "      <th>acceleration_long_min</th>\n",
       "      <th>acceleration_long_max</th>\n",
       "      <th>label</th>\n",
       "      <th>dsd_score</th>\n",
       "      <th>Speed_mean</th>\n",
       "      <th>Speed_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bookingID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1073741824054</th>\n",
       "      <td>3.598824</td>\n",
       "      <td>0.424268</td>\n",
       "      <td>-0.005870</td>\n",
       "      <td>-2.965</td>\n",
       "      <td>2.268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087165</td>\n",
       "      <td>6.684724</td>\n",
       "      <td>19.299793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185410973787</th>\n",
       "      <td>7.088677</td>\n",
       "      <td>27.057858</td>\n",
       "      <td>-0.011346</td>\n",
       "      <td>-30.100</td>\n",
       "      <td>5.030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147378</td>\n",
       "      <td>9.671239</td>\n",
       "      <td>29.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163208757379</th>\n",
       "      <td>42.344887</td>\n",
       "      <td>55.522868</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>-4.911</td>\n",
       "      <td>3.520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097054</td>\n",
       "      <td>4.067107</td>\n",
       "      <td>17.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884763262976</th>\n",
       "      <td>5.535051</td>\n",
       "      <td>2.984581</td>\n",
       "      <td>-0.005857</td>\n",
       "      <td>-11.895</td>\n",
       "      <td>13.399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054181</td>\n",
       "      <td>5.675100</td>\n",
       "      <td>18.217026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300647710810</th>\n",
       "      <td>4.473469</td>\n",
       "      <td>1.297247</td>\n",
       "      <td>-0.016612</td>\n",
       "      <td>-10.153</td>\n",
       "      <td>8.287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083391</td>\n",
       "      <td>11.943424</td>\n",
       "      <td>27.638723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy_mean  Accuracy_std  acceleration_long_mean  \\\n",
       "bookingID                                                            \n",
       "1073741824054       3.598824      0.424268               -0.005870   \n",
       "1185410973787       7.088677     27.057858               -0.011346   \n",
       "163208757379       42.344887     55.522868                0.008301   \n",
       "884763262976        5.535051      2.984581               -0.005857   \n",
       "300647710810        4.473469      1.297247               -0.016612   \n",
       "\n",
       "               acceleration_long_min  acceleration_long_max  label  dsd_score  \\\n",
       "bookingID                                                                       \n",
       "1073741824054                 -2.965                  2.268    0.0   0.087165   \n",
       "1185410973787                -30.100                  5.030    0.0   0.147378   \n",
       "163208757379                  -4.911                  3.520    0.0   0.097054   \n",
       "884763262976                 -11.895                 13.399    0.0   0.054181   \n",
       "300647710810                 -10.153                  8.287    0.0   0.083391   \n",
       "\n",
       "               Speed_mean  Speed_max  \n",
       "bookingID                             \n",
       "1073741824054    6.684724  19.299793  \n",
       "1185410973787    9.671239  29.310000  \n",
       "163208757379     4.067107  17.170000  \n",
       "884763262976     5.675100  18.217026  \n",
       "300647710810    11.943424  27.638723  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binning and One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define bin intervals\n",
    "Speed_bin = pd.IntervalIndex.from_tuples([(df.Speed_max.min()-1,2.2352),(2.2352,6.7056),(6.7056,13.4112),(13.4112,17.8816),(17.8816,df.Speed_max.max()+1)])\n",
    "Acceleration_bin = pd.IntervalIndex.from_tuples([(df.acceleration_long_min.min()-1,-3.1),(-3.1,2.6),(2.6,df.acceleration_long_max.max()+1)])\n",
    "dsd_score_bin = pd.IntervalIndex.from_tuples([(df.dsd_score.min()-0.1,0.09),(0.09, df.dsd_score.max()+0.1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binning the following variables\n",
    "df['Speed_mean_bin'] = pd.cut(df.loc[:,'Speed_mean'], bins = Speed_bin, labels = (range(1,len(Speed_bin)-1)))\n",
    "df['Speed_max_bin'] = pd.cut(df.loc[:,'Speed_max'], bins = Speed_bin, labels = (range(1,len(Speed_bin)-1)))\n",
    "df['acceleration_mean_bin'] = pd.cut(df.loc[:,'acceleration_long_mean'], bins = Acceleration_bin, labels = (range(1,len(Acceleration_bin)-1)))\n",
    "df['acceleration_min_bin'] = pd.cut(df.loc[:,'acceleration_long_min'], bins = Acceleration_bin, labels = (range(1,len(Acceleration_bin)-1)))\n",
    "df['acceleration_max_bin'] = pd.cut(df.loc[:,'acceleration_long_max'], bins = Acceleration_bin, labels = (range(1,len(Acceleration_bin)-1)))\n",
    "df['dsd_score_bin'] = pd.cut(df.loc[:,'dsd_score'], bins = dsd_score_bin, labels = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying one hot encoding\n",
    "ohe = pd.get_dummies(df.loc[:, ['Speed_mean_bin','Speed_max_bin','dsd_score_bin','acceleration_mean_bin','acceleration_min_bin','acceleration_max_bin']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.drop(columns = 'dsd_score_bin_(-0.1, 0.09]', inplace = True)\n",
    "#ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>acceleration_long_mean</th>\n",
       "      <th>acceleration_long_min</th>\n",
       "      <th>acceleration_long_max</th>\n",
       "      <th>label</th>\n",
       "      <th>dsd_score</th>\n",
       "      <th>Speed_mean</th>\n",
       "      <th>Speed_max</th>\n",
       "      <th>Speed_mean_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>dsd_score_bin_(0.09, 0.551737451737]</th>\n",
       "      <th>acceleration_mean_bin_(-57.699, -3.1]</th>\n",
       "      <th>acceleration_mean_bin_(-3.1, 2.6]</th>\n",
       "      <th>acceleration_mean_bin_(2.6, 143.986]</th>\n",
       "      <th>acceleration_min_bin_(-57.699, -3.1]</th>\n",
       "      <th>acceleration_min_bin_(-3.1, 2.6]</th>\n",
       "      <th>acceleration_min_bin_(2.6, 143.986]</th>\n",
       "      <th>acceleration_max_bin_(-57.699, -3.1]</th>\n",
       "      <th>acceleration_max_bin_(-3.1, 2.6]</th>\n",
       "      <th>acceleration_max_bin_(2.6, 143.986]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bookingID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1073741824054</th>\n",
       "      <td>3.598824</td>\n",
       "      <td>0.424268</td>\n",
       "      <td>-0.005870</td>\n",
       "      <td>-2.965</td>\n",
       "      <td>2.268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087165</td>\n",
       "      <td>6.684724</td>\n",
       "      <td>19.299793</td>\n",
       "      <td>(2.2352, 6.7056]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185410973787</th>\n",
       "      <td>7.088677</td>\n",
       "      <td>27.057858</td>\n",
       "      <td>-0.011346</td>\n",
       "      <td>-30.100</td>\n",
       "      <td>5.030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147378</td>\n",
       "      <td>9.671239</td>\n",
       "      <td>29.310000</td>\n",
       "      <td>(6.7056, 13.4112]</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163208757379</th>\n",
       "      <td>42.344887</td>\n",
       "      <td>55.522868</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>-4.911</td>\n",
       "      <td>3.520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097054</td>\n",
       "      <td>4.067107</td>\n",
       "      <td>17.170000</td>\n",
       "      <td>(2.2352, 6.7056]</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884763262976</th>\n",
       "      <td>5.535051</td>\n",
       "      <td>2.984581</td>\n",
       "      <td>-0.005857</td>\n",
       "      <td>-11.895</td>\n",
       "      <td>13.399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054181</td>\n",
       "      <td>5.675100</td>\n",
       "      <td>18.217026</td>\n",
       "      <td>(2.2352, 6.7056]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300647710810</th>\n",
       "      <td>4.473469</td>\n",
       "      <td>1.297247</td>\n",
       "      <td>-0.016612</td>\n",
       "      <td>-10.153</td>\n",
       "      <td>8.287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083391</td>\n",
       "      <td>11.943424</td>\n",
       "      <td>27.638723</td>\n",
       "      <td>(6.7056, 13.4112]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy_mean  Accuracy_std  acceleration_long_mean  \\\n",
       "bookingID                                                            \n",
       "1073741824054       3.598824      0.424268               -0.005870   \n",
       "1185410973787       7.088677     27.057858               -0.011346   \n",
       "163208757379       42.344887     55.522868                0.008301   \n",
       "884763262976        5.535051      2.984581               -0.005857   \n",
       "300647710810        4.473469      1.297247               -0.016612   \n",
       "\n",
       "               acceleration_long_min  acceleration_long_max  label  dsd_score  \\\n",
       "bookingID                                                                       \n",
       "1073741824054                 -2.965                  2.268    0.0   0.087165   \n",
       "1185410973787                -30.100                  5.030    0.0   0.147378   \n",
       "163208757379                  -4.911                  3.520    0.0   0.097054   \n",
       "884763262976                 -11.895                 13.399    0.0   0.054181   \n",
       "300647710810                 -10.153                  8.287    0.0   0.083391   \n",
       "\n",
       "               Speed_mean  Speed_max     Speed_mean_bin  \\\n",
       "bookingID                                                 \n",
       "1073741824054    6.684724  19.299793   (2.2352, 6.7056]   \n",
       "1185410973787    9.671239  29.310000  (6.7056, 13.4112]   \n",
       "163208757379     4.067107  17.170000   (2.2352, 6.7056]   \n",
       "884763262976     5.675100  18.217026   (2.2352, 6.7056]   \n",
       "300647710810    11.943424  27.638723  (6.7056, 13.4112]   \n",
       "\n",
       "                              ...                   \\\n",
       "bookingID                     ...                    \n",
       "1073741824054                 ...                    \n",
       "1185410973787                 ...                    \n",
       "163208757379                  ...                    \n",
       "884763262976                  ...                    \n",
       "300647710810                  ...                    \n",
       "\n",
       "              dsd_score_bin_(0.09, 0.551737451737]  \\\n",
       "bookingID                                            \n",
       "1073741824054                                    0   \n",
       "1185410973787                                    1   \n",
       "163208757379                                     1   \n",
       "884763262976                                     0   \n",
       "300647710810                                     0   \n",
       "\n",
       "              acceleration_mean_bin_(-57.699, -3.1]  \\\n",
       "bookingID                                             \n",
       "1073741824054                                     0   \n",
       "1185410973787                                     0   \n",
       "163208757379                                      0   \n",
       "884763262976                                      0   \n",
       "300647710810                                      0   \n",
       "\n",
       "              acceleration_mean_bin_(-3.1, 2.6]  \\\n",
       "bookingID                                         \n",
       "1073741824054                                 1   \n",
       "1185410973787                                 1   \n",
       "163208757379                                  1   \n",
       "884763262976                                  1   \n",
       "300647710810                                  1   \n",
       "\n",
       "              acceleration_mean_bin_(2.6, 143.986]  \\\n",
       "bookingID                                            \n",
       "1073741824054                                    0   \n",
       "1185410973787                                    0   \n",
       "163208757379                                     0   \n",
       "884763262976                                     0   \n",
       "300647710810                                     0   \n",
       "\n",
       "              acceleration_min_bin_(-57.699, -3.1]  \\\n",
       "bookingID                                            \n",
       "1073741824054                                    0   \n",
       "1185410973787                                    1   \n",
       "163208757379                                     1   \n",
       "884763262976                                     1   \n",
       "300647710810                                     1   \n",
       "\n",
       "               acceleration_min_bin_(-3.1, 2.6]  \\\n",
       "bookingID                                         \n",
       "1073741824054                                 1   \n",
       "1185410973787                                 0   \n",
       "163208757379                                  0   \n",
       "884763262976                                  0   \n",
       "300647710810                                  0   \n",
       "\n",
       "               acceleration_min_bin_(2.6, 143.986]  \\\n",
       "bookingID                                            \n",
       "1073741824054                                    0   \n",
       "1185410973787                                    0   \n",
       "163208757379                                     0   \n",
       "884763262976                                     0   \n",
       "300647710810                                     0   \n",
       "\n",
       "               acceleration_max_bin_(-57.699, -3.1]  \\\n",
       "bookingID                                             \n",
       "1073741824054                                     0   \n",
       "1185410973787                                     0   \n",
       "163208757379                                      0   \n",
       "884763262976                                      0   \n",
       "300647710810                                      0   \n",
       "\n",
       "               acceleration_max_bin_(-3.1, 2.6]  \\\n",
       "bookingID                                         \n",
       "1073741824054                                 1   \n",
       "1185410973787                                 0   \n",
       "163208757379                                  0   \n",
       "884763262976                                  0   \n",
       "300647710810                                  0   \n",
       "\n",
       "               acceleration_max_bin_(2.6, 143.986]  \n",
       "bookingID                                           \n",
       "1073741824054                                    0  \n",
       "1185410973787                                    1  \n",
       "163208757379                                     1  \n",
       "884763262976                                     1  \n",
       "300647710810                                     1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df,ohe], axis=1)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df_cols = []\n",
    "for i,col in enumerate(df.columns, start = 1):\n",
    "    #print(col)\n",
    "    df_cols.append(re.sub(r\"\\(.*]$\", str(i), col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['Accuracy_mean', 'Accuracy_std']] = scaler.fit_transform(df.loc[:,['Accuracy_mean', 'Accuracy_std']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Accuracy_std</th>\n",
       "      <th>acceleration_long_mean</th>\n",
       "      <th>acceleration_long_min</th>\n",
       "      <th>acceleration_long_max</th>\n",
       "      <th>label</th>\n",
       "      <th>dsd_score</th>\n",
       "      <th>Speed_mean</th>\n",
       "      <th>Speed_max</th>\n",
       "      <th>Speed_mean_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>dsd_score_bin_26</th>\n",
       "      <th>acceleration_mean_bin_27</th>\n",
       "      <th>acceleration_mean_bin_28</th>\n",
       "      <th>acceleration_mean_bin_29</th>\n",
       "      <th>acceleration_min_bin_30</th>\n",
       "      <th>acceleration_min_bin_31</th>\n",
       "      <th>acceleration_min_bin_32</th>\n",
       "      <th>acceleration_max_bin_33</th>\n",
       "      <th>acceleration_max_bin_34</th>\n",
       "      <th>acceleration_max_bin_35</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bookingID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1073741824054</th>\n",
       "      <td>-0.179569</td>\n",
       "      <td>-0.209608</td>\n",
       "      <td>-0.005870</td>\n",
       "      <td>-2.965</td>\n",
       "      <td>2.268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087165</td>\n",
       "      <td>6.684724</td>\n",
       "      <td>19.299793</td>\n",
       "      <td>(2.2352, 6.7056]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185410973787</th>\n",
       "      <td>-0.089743</td>\n",
       "      <td>0.208117</td>\n",
       "      <td>-0.011346</td>\n",
       "      <td>-30.100</td>\n",
       "      <td>5.030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147378</td>\n",
       "      <td>9.671239</td>\n",
       "      <td>29.310000</td>\n",
       "      <td>(6.7056, 13.4112]</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163208757379</th>\n",
       "      <td>0.817729</td>\n",
       "      <td>0.654567</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>-4.911</td>\n",
       "      <td>3.520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097054</td>\n",
       "      <td>4.067107</td>\n",
       "      <td>17.170000</td>\n",
       "      <td>(2.2352, 6.7056]</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884763262976</th>\n",
       "      <td>-0.129732</td>\n",
       "      <td>-0.169451</td>\n",
       "      <td>-0.005857</td>\n",
       "      <td>-11.895</td>\n",
       "      <td>13.399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054181</td>\n",
       "      <td>5.675100</td>\n",
       "      <td>18.217026</td>\n",
       "      <td>(2.2352, 6.7056]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300647710810</th>\n",
       "      <td>-0.157056</td>\n",
       "      <td>-0.195916</td>\n",
       "      <td>-0.016612</td>\n",
       "      <td>-10.153</td>\n",
       "      <td>8.287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083391</td>\n",
       "      <td>11.943424</td>\n",
       "      <td>27.638723</td>\n",
       "      <td>(6.7056, 13.4112]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Accuracy_mean  Accuracy_std  acceleration_long_mean  \\\n",
       "bookingID                                                            \n",
       "1073741824054      -0.179569     -0.209608               -0.005870   \n",
       "1185410973787      -0.089743      0.208117               -0.011346   \n",
       "163208757379        0.817729      0.654567                0.008301   \n",
       "884763262976       -0.129732     -0.169451               -0.005857   \n",
       "300647710810       -0.157056     -0.195916               -0.016612   \n",
       "\n",
       "               acceleration_long_min  acceleration_long_max  label  dsd_score  \\\n",
       "bookingID                                                                       \n",
       "1073741824054                 -2.965                  2.268    0.0   0.087165   \n",
       "1185410973787                -30.100                  5.030    0.0   0.147378   \n",
       "163208757379                  -4.911                  3.520    0.0   0.097054   \n",
       "884763262976                 -11.895                 13.399    0.0   0.054181   \n",
       "300647710810                 -10.153                  8.287    0.0   0.083391   \n",
       "\n",
       "               Speed_mean  Speed_max     Speed_mean_bin  \\\n",
       "bookingID                                                 \n",
       "1073741824054    6.684724  19.299793   (2.2352, 6.7056]   \n",
       "1185410973787    9.671239  29.310000  (6.7056, 13.4112]   \n",
       "163208757379     4.067107  17.170000   (2.2352, 6.7056]   \n",
       "884763262976     5.675100  18.217026   (2.2352, 6.7056]   \n",
       "300647710810    11.943424  27.638723  (6.7056, 13.4112]   \n",
       "\n",
       "                        ...            dsd_score_bin_26  \\\n",
       "bookingID               ...                               \n",
       "1073741824054           ...                           0   \n",
       "1185410973787           ...                           1   \n",
       "163208757379            ...                           1   \n",
       "884763262976            ...                           0   \n",
       "300647710810            ...                           0   \n",
       "\n",
       "              acceleration_mean_bin_27 acceleration_mean_bin_28  \\\n",
       "bookingID                                                         \n",
       "1073741824054                        0                        1   \n",
       "1185410973787                        0                        1   \n",
       "163208757379                         0                        1   \n",
       "884763262976                         0                        1   \n",
       "300647710810                         0                        1   \n",
       "\n",
       "              acceleration_mean_bin_29 acceleration_min_bin_30  \\\n",
       "bookingID                                                        \n",
       "1073741824054                        0                       0   \n",
       "1185410973787                        0                       1   \n",
       "163208757379                         0                       1   \n",
       "884763262976                         0                       1   \n",
       "300647710810                         0                       1   \n",
       "\n",
       "               acceleration_min_bin_31  acceleration_min_bin_32  \\\n",
       "bookingID                                                         \n",
       "1073741824054                        1                        0   \n",
       "1185410973787                        0                        0   \n",
       "163208757379                         0                        0   \n",
       "884763262976                         0                        0   \n",
       "300647710810                         0                        0   \n",
       "\n",
       "               acceleration_max_bin_33  acceleration_max_bin_34  \\\n",
       "bookingID                                                         \n",
       "1073741824054                        0                        1   \n",
       "1185410973787                        0                        0   \n",
       "163208757379                         0                        0   \n",
       "884763262976                         0                        0   \n",
       "300647710810                         0                        0   \n",
       "\n",
       "               acceleration_max_bin_35  \n",
       "bookingID                               \n",
       "1073741824054                        0  \n",
       "1185410973787                        1  \n",
       "163208757379                         1  \n",
       "884763262976                         1  \n",
       "300647710810                         1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label = df.label.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['acceleration_long_mean',\n",
    "       'acceleration_long_min', 'acceleration_long_max', 'label', 'Speed_mean',\n",
    "       'Speed_max', 'Speed_mean_bin', 'Speed_max_bin', 'dsd_score_bin',\n",
    "       'acceleration_mean_bin', 'acceleration_min_bin', 'acceleration_max_bin']\n",
    "X = df.loc[:, df.columns.difference(exclude)]\n",
    "y = df.label\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, stratify=y, random_state = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] subsample=1.0, max_depth=3, min_child_weight=5, colsample_bytree=0.8, gamma=1.5 \n",
      "[CV] subsample=1.0, max_depth=3, min_child_weight=5, colsample_bytree=0.8, gamma=1.5 \n",
      "[CV] subsample=1.0, max_depth=3, min_child_weight=5, colsample_bytree=0.8, gamma=1.5 \n",
      "[CV] subsample=1.0, max_depth=3, min_child_weight=5, colsample_bytree=0.8, gamma=1.5 \n",
      "[CV] subsample=1.0, max_depth=3, min_child_weight=5, colsample_bytree=0.8, gamma=1.5 \n",
      "[CV] subsample=1.0, max_depth=4, min_child_weight=5, colsample_bytree=0.6, gamma=1.5 \n",
      "[CV] subsample=1.0, max_depth=4, min_child_weight=5, colsample_bytree=0.6, gamma=1.5 \n",
      "[CV] subsample=1.0, max_depth=4, min_child_weight=5, colsample_bytree=0.6, gamma=1.5 \n",
      "[CV] subsample=1.0, max_depth=4, min_child_weight=5, colsample_bytree=0.6, gamma=1.5 \n",
      "[CV] subsample=1.0, max_depth=4, min_child_weight=5, colsample_bytree=0.6, gamma=1.5 \n",
      "[CV] subsample=0.6, max_depth=4, min_child_weight=5, colsample_bytree=0.8, gamma=5 \n",
      "[CV] subsample=0.6, max_depth=4, min_child_weight=5, colsample_bytree=0.8, gamma=5 \n",
      "[CV] subsample=0.6, max_depth=4, min_child_weight=5, colsample_bytree=0.8, gamma=5 \n",
      "[CV] subsample=0.6, max_depth=4, min_child_weight=5, colsample_bytree=0.8, gamma=5 \n",
      "[CV] subsample=0.8, max_depth=5, min_child_weight=5, colsample_bytree=1.0, gamma=2 \n",
      "[CV] subsample=0.8, max_depth=5, min_child_weight=5, colsample_bytree=1.0, gamma=2 \n",
      "[CV] subsample=0.6, max_depth=4, min_child_weight=5, colsample_bytree=0.8, gamma=5 \n",
      "[CV] subsample=0.8, max_depth=5, min_child_weight=5, colsample_bytree=1.0, gamma=2 \n",
      "[CV] subsample=0.8, max_depth=5, min_child_weight=5, colsample_bytree=1.0, gamma=2 \n",
      "[CV] subsample=0.8, max_depth=5, min_child_weight=5, colsample_bytree=1.0, gamma=2 \n",
      "[CV] subsample=0.6, max_depth=3, min_child_weight=1, colsample_bytree=1.0, gamma=5 \n",
      "[CV] subsample=0.6, max_depth=3, min_child_weight=1, colsample_bytree=1.0, gamma=5 \n",
      "[CV] subsample=0.6, max_depth=3, min_child_weight=1, colsample_bytree=1.0, gamma=5 \n",
      "[CV] subsample=0.6, max_depth=3, min_child_weight=1, colsample_bytree=1.0, gamma=5 \n",
      "[CV] subsample=0.6, max_depth=3, min_child_weight=1, colsample_bytree=1.0, gamma=5 \n",
      "[CV]  subsample=0.6, max_depth=3, min_child_weight=1, colsample_bytree=1.0, gamma=5, score=0.6080445906432748, total=76.0min\n",
      "[CV]  subsample=1.0, max_depth=3, min_child_weight=5, colsample_bytree=0.8, gamma=1.5, score=0.6108816311612364, total=76.6min\n",
      "[CV]  subsample=1.0, max_depth=3, min_child_weight=5, colsample_bytree=0.8, gamma=1.5, score=0.6120620626641277, total=77.3min\n",
      "[CV]  subsample=0.6, max_depth=3, min_child_weight=1, colsample_bytree=1.0, gamma=5, score=0.6271458071936429, total=78.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of  25 | elapsed: 78.4min remaining: 411.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=1.0, max_depth=3, min_child_weight=5, colsample_bytree=0.8, gamma=1.5, score=0.6129101317440402, total=82.2min\n",
      "[CV]  subsample=0.6, max_depth=3, min_child_weight=1, colsample_bytree=1.0, gamma=5, score=0.6148889063153493, total=85.4min\n",
      "[CV]  subsample=0.6, max_depth=3, min_child_weight=1, colsample_bytree=1.0, gamma=5, score=0.6137022274546641, total=86.6min\n",
      "[CV]  subsample=1.0, max_depth=3, min_child_weight=5, colsample_bytree=0.8, gamma=1.5, score=0.6065668130489335, total=87.6min\n",
      "[CV]  subsample=1.0, max_depth=4, min_child_weight=5, colsample_bytree=0.6, gamma=1.5, score=0.611672156001673, total=88.7min\n",
      "[CV]  subsample=1.0, max_depth=4, min_child_weight=5, colsample_bytree=0.6, gamma=1.5, score=0.6186870033458803, total=89.1min\n",
      "[CV]  subsample=1.0, max_depth=4, min_child_weight=5, colsample_bytree=0.6, gamma=1.5, score=0.600142461313258, total=89.3min\n",
      "[CV]  subsample=0.6, max_depth=3, min_child_weight=1, colsample_bytree=1.0, gamma=5, score=0.6106098389795065, total=90.0min\n",
      "[CV]  subsample=1.0, max_depth=3, min_child_weight=5, colsample_bytree=0.8, gamma=1.5, score=0.6219991635299038, total=90.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  13 out of  25 | elapsed: 90.9min remaining: 83.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.6, max_depth=4, min_child_weight=5, colsample_bytree=0.8, gamma=5, score=0.6151372333751568, total=92.2min\n",
      "[CV]  subsample=0.6, max_depth=4, min_child_weight=5, colsample_bytree=0.8, gamma=5, score=0.6266535968214135, total=93.0min\n",
      "[CV]  subsample=0.6, max_depth=4, min_child_weight=5, colsample_bytree=0.8, gamma=5, score=0.6065298663324981, total=93.6min\n",
      "[CV]  subsample=1.0, max_depth=4, min_child_weight=5, colsample_bytree=0.6, gamma=1.5, score=0.6076651030359262, total=94.4min\n",
      "[CV]  subsample=0.6, max_depth=4, min_child_weight=5, colsample_bytree=0.8, gamma=5, score=0.6089342848180679, total=94.5min\n",
      "[CV]  subsample=1.0, max_depth=4, min_child_weight=5, colsample_bytree=0.6, gamma=1.5, score=0.6051407163742689, total=94.7min\n",
      "[CV]  subsample=0.6, max_depth=4, min_child_weight=5, colsample_bytree=0.8, gamma=5, score=0.6125774907256946, total=95.1min\n",
      "[CV]  subsample=0.8, max_depth=5, min_child_weight=5, colsample_bytree=1.0, gamma=2, score=0.6105738327816431, total=96.4min\n",
      "[CV]  subsample=0.8, max_depth=5, min_child_weight=5, colsample_bytree=1.0, gamma=2, score=0.6025611668757842, total=97.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  22 out of  25 | elapsed: 97.1min remaining: 13.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.8, max_depth=5, min_child_weight=5, colsample_bytree=1.0, gamma=2, score=0.6249239335006272, total=97.0min\n",
      "[CV]  subsample=0.8, max_depth=5, min_child_weight=5, colsample_bytree=1.0, gamma=2, score=0.6068402777777777, total=97.1min\n",
      "[CV]  subsample=0.8, max_depth=5, min_child_weight=5, colsample_bytree=1.0, gamma=2, score=0.6062965286491008, total=97.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed: 97.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x7ff397aca728>,\n",
       "          error_score='raise',\n",
       "          estimator=XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.02, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=600, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1),\n",
       "          fit_params=None, iid=True, n_iter=5, n_jobs=-1,\n",
       "          param_distributions={'subsample': [0.6, 0.8, 1.0], 'max_depth': [3, 4, 5], 'min_child_weight': [1, 5, 10], 'colsample_bytree': [0.6, 0.8, 1.0], 'gamma': [0.5, 1, 1.5, 2, 5]},\n",
       "          pre_dispatch='2*n_jobs', random_state=36, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = 5\n",
    "param_comb = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=33)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=-1,\n",
    "                                   cv=skf.split(X_train, y_train), verbose=3, random_state=36)\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1.0,\n",
       "       gamma=5, learning_rate=0.02, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=600, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=0.6)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61487792018317344"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.27015978,  0.26272762,  0.00185805,  0.0245262 ,  0.01003344,\n",
       "        0.02266815,  0.01560758,  0.03381642,  0.02564103,  0.00929023,\n",
       "        0.0122631 ,  0.03939056,  0.        ,  0.02712746,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.02787068,  0.        ,\n",
       "        0.        ,  0.21701969,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Accuracy_mean', 'Accuracy_std', 'Speed_max_bin_21', 'Speed_max_bin_22',\n",
       "       'Speed_max_bin_23', 'Speed_max_bin_24', 'Speed_max_bin_25',\n",
       "       'Speed_mean_bin_16', 'Speed_mean_bin_17', 'Speed_mean_bin_18',\n",
       "       'Speed_mean_bin_19', 'Speed_mean_bin_20', 'acceleration_max_bin_33',\n",
       "       'acceleration_max_bin_34', 'acceleration_max_bin_35',\n",
       "       'acceleration_mean_bin_27', 'acceleration_mean_bin_28',\n",
       "       'acceleration_mean_bin_29', 'acceleration_min_bin_30',\n",
       "       'acceleration_min_bin_31', 'acceleration_min_bin_32', 'dsd_score',\n",
       "       'dsd_score_bin_26'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'gamma': 5,\n",
       " 'learning_rate': 0.02,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 600,\n",
       " 'nthread': -1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'seed': 0,\n",
       " 'silent': True,\n",
       " 'subsample': 0.6}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
